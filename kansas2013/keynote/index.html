<!DOCTYPE HTML>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <title>Fabrications, or How to Lie with Computer Vision | Jentery Sayers</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link href='http://fonts.googleapis.com/css?family=Noto+Sans:400,700,400italic|Noto+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" href="reveal.min.css">
		<link rel="stylesheet" href="theme.css" id="theme">
</head>
<body>
<div class="reveal">
<div class="slides">

<section>

<section id="title" data-background="skanect.png">
  <h1>Fabrications, or<br/>How to Lie with Computer Vision</h1>
 <h3>University of Kansas | 14 September 2013<br />
  Digital Humanities Forum Keynote</h3>
  <h3><a href="http://www.jenterysayers.com/" target="_blank">Jentery Sayers</a> | <a href="http://english.uvic.ca/" target="_blank">U. of Victoria</a> | <a href="https://twitter.com/jenterysayers" target="_blank">@jenterysayers</a></h3>
  <p><strong>–– Use your spacebar or arrow keys to navigate this slidedeck. ––</strong><br />
  <strong>Slidedeck revised 2-4 October 2013 for publication online.</strong><br />
   <strong><a href="https://github.com/uvicmakerlab/conferenceMaterials/tree/gh-pages/kansas2013/keynote" target="_blank">Fork this presentation.</a></strong></p>
</section>

<section id="intro" data-background="skanect.png">
<h3>image made using <a href="http://skanect.manctl.com/" target="_blank">Skanect</a>, c/o <a href="http://maker.uvic.ca/" target="_blank">The Maker Lab</a></h3>
</section>

</section>
 
<section>

<section class="transparent" id="helloworld" data-background="helloWorldFailedPrint.jpg"></section>

<section id="today" data-background="helloWorldFailedPrint.jpg">
  	<h1>Today</h1>
  	<h3>Some example computer vision projects</h3>
	<h3>The question of computer vision and culture</h3>
	<h3>Some intersections with digital humanities</h3>
	<h3>Two "Z-Axis" projects from The Maker Lab</h3> 
</section> 

</section>

<section>

 <section id="computervision" data-background="arduinoCV.jpg">
  <h1>Computer Vision</h1>
  <h3>the automated description and reconstruction<br />of the physical world through algorithms</h3> 
  <h3>(image c/o <a href="http://www.instructables.com/id/Face-detection-and-tracking-with-Arduino-and-OpenC/" target="_blank">Instructables</a>)</h3>
</section> 

 <section id="cvexamples" data-background="arduinoCV.jpg">
  <h1>Some Examples</h1>
</section>

 <section id="captcha" data-background="captcha.png">
  <h1>CAPTCHAs</h1>
  <h3>Completely Automated Public Turing test<br />to tell Computers and Humans Apart</h3>
  <h3>(image c/o <a href="http://www.softwaresecretweapons.com/jspwiki/attach/WaterCap_Strong_PHP_CAPTCHA_With_Negative_Spaces_And_Shadows/other.png" target="_blank">Pavel Simakov</a>;<br />CAPTCHA c/o Carnegie Mellon)</h3> 
</section>

<section id="detection" data-background="facedetection.png">
  <h1>Face Detection</h1>
  <h3>(<a href="https://vimeo.com/12774628" target="_blank">video</a> by Adam Harvey)</h3>
  </section>

   <section class="transparent" id="facedetection" data-background="facedetection.png">
<iframe src="//player.vimeo.com/video/12774628" width="750" height="716" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></section>

 <section id="catch" data-background="catch.png">
  <h1>Photogrammetry</h1>
  <h3>Stitching together component parts</h3>
  <h3>(image made w/ <a href="http://www.123dapp.com/catch" target="_blank">123D Catch</a>, c/o <a href="http://maker.uvic.ca/" target="_blank">The Maker Lab</a>)</h3> 
</section> 

 <section id="crowdsourced3D" data-background="linked.jpg">
  <h1>Crowdsourced<br />Sculpture</h1>
  <h3>Assembling custom parts made<br />across geographical distance</h3>
  <h3>(image c/o <a href="http://www.printtopeer.com/sculpture" target="_blank">PrintToPeer</a> + <a href="http://jeffdeboer.com/" target="_blank">Jeff de Boer</a>)</h3> 
</section>

 <section id="surveillance" data-background="surveillance.png">
  <h1>Surveillance Forensics</h1>
  <h3>extract trajectories and snapshots from video</h3>
  <h3>(image c/o <a href="http://www.computervisiononline.com/dataset/3dpes-people-surveillance-dataset" target="_blank">Computer Vision Online</a>)</h3>
</section>

 <section id="uav" data-background="arduwiino.jpg">
  <h1>Unmanned AVs</h1>
  <h3>point-and-click waypoints and scripted missions</h3>
  <h3>(image c/o <a href="http://www.rcgroups.com/forums/showthread.php?t=1332876" target="_blank">RCGroups</a>; see also <a href="http://diydrones.com/" target="_blank">DIY Drones</a>)</h3>
</section>

 <section id="minsky" data-background="minskytron.jpg">
  <h1>Marvin Minsky and Gerald Jay Sussman</h1>
  <h3>"linking a camera to a computer and getting the camera to describe what it saw"</h3>
  <h3>(ca. 1966, at MIT | see <a href="http://szeliski.org/Book/" target="_blank">Szeliski 2010</a>)</h3> 
</section>
</section>

<!-- section id="winston" data-background="physchologyOfComputerVision.jpg">
<h1>Patrick Henry Winston</h1> 
<h3>" 
(1970s, MIT, see Winston 1975)
</section>
<section id=marr" data-background=" ">
<h1>David Marr</h1> 
<h3>" 
(1982, )
</section--> 

<section>
<section class="transparent" id="printrbot" data-background="dhsi2013PrinterModelUVic.png"></section> 
<section id="culture" data-background="dhsi2013PrinterModelUVic.png">
<h1>Computer Vision:<br />Cultural Perspectives</h1> 
<h3>What's At Stake? Politically? Aesthetically?</h3> 
</section> 

<section id="sensorvernacular" data-background="spring.gif">
<h1>Sensor-Vernacular</h1> 
<h3>the grain of seeing, the grain of computation</h3> 
<h3>(for commentary + image, see<br /><a href="http://berglondon.com/blog/2011/05/13/sensor-vernacular/" target="_blank">Jones 2011</a> and <a href="http://stunlaw.blogspot.ca/2012/04/abduction-aesthetic-computationality.html" target="_blank">Berry 2013</a>)</h3> 
</section> 

<section id="newaesthetic" data-background="shipAdrift.png">
<h1>The New Aesthetic</h1> 
<h3>machine vision supplants human vision</h3> 
<h3>(c/o <a href="http://shorttermmemoryloss.com/portfolio/project/a-ship-adrift/" target="_blank">Bridle 2011</a>; also see <a href="http://emergenceofdhbook.tumblr.com/" target="_blank">Jones 2013</a>)</h3> 
</section> 

<section id="ENIAC" data-background="womenOfENIAC.jpg">
<h1>The Women of ENIAC</h1> 
<h3>"nameless disappearing computer operators"</h3> 
<h3>(1940s, Penn + Aberdeen | see <a href="http://books.google.ca/books?id=n15KIako-s4C&pg=PA34&lpg=PA34&dq=%22nameless+disappearing+computer+operators%22&source=bl&ots=RUqGw_lt5k&sig=8j1GQniMxHEVbBzn-TwikeWDxlU&hl=en&sa=X&ei=j-FOUuX8AoeTiAKd84G4AQ&ved=0CC4Q6AEwAA#v=onepage&q=%22nameless%20disappearing%20computer%20operators%22&f=false" target="_blank">Chun 2011</a>)</h3> 
</section>

<section id="browne" data-background="sbrowne.png">
<h1>Racial Profiling and Biometrics</h1> 
<h3>"falsify the idea that certain surveillance technologies and their application<br /> are always neutral"</h3> 
<h3>(see <a href="http://crs.sagepub.com/content/36/1/131.refs" target="_blank">Browne 2010</a>)</h3> 
</section>

<section id="opencv" data-background="opencv2.png">
<h1>OpenCV</h1> 
<h3>"make it easy to experiment with<br /> the most common computer vision tools"</h3> 
<h3>(see <a href="http://urbanhonking.com/ideasfordozens/2013/07/10/announcing-opencv-for-processing/" target="_blank">Borenstein 2013</a>)</h3> 
</section> 
</section> 

<section>
<section class="transparent" id="parts" data-background="dhsi2013Printer3UVic.jpg"></section> 
<section id="dh" data-background="dhsi2013Printer3UVic.jpg">
<h1>Learning from<br />Existing DH Projects</h1> 
<h3>speculative computing + expressive models</h3> 
</section> 

<section id="speccpu" data-background="speccomputing.png">
<h1>Speculative Computing</h1> 
<h3>"place the hermeneutic inside a visual and algorithmic system"</h3>
<h3>(see <a href="http://www.digitalhumanities.org/companion/view?docId=blackwell/9781405103213/9781405103213.xml&chunk.id=ss1-4-10" target="_blank">Drucker and Nowviskie 2004</a>)</h3> 
</section> 

<section id="sample" data-background="sample.png">
<h1>Non-Consumptive Reading</h1> 
<h3>"Make the computer model itself<br /> an expressive object."</h3>
<h3>(see <a href="http://www.samplereality.com/2013/05/22/the-poetics-of-non-consumptive-reading/" target="_blank">Sample 2013</a>)</h3> 
</section> 
</section>

<section>
<section class="transparent" id="glitch" data-background="glitch.jpg"></section> 
<section id="mlab" data-background="glitch.jpg">
<h1>Z-Axis in the MLab</h1> 
<h3>two example Maker Lab projects<br />engaging computer vision</h3>
<h3>(image care of <a href="http://maker.uvic.ca/snes/" target="_blank">Jon Olaf Johnson</a>)</h3> 
</section> 

<section id="maps" data-background="zposter.png">
<h1>Warped Modernisms</h1> 
<h3>z-axis attempts to express time spent reading;<br />maps warped using CV + 3D sculpture techniques</h3>
<h3>(sparked by <a href="http://maker.uvic.ca/zposter/" target="_blank">Alex Christie, Arthur Hain, <br />and Katie Tanigawa 2013</a>)</h3> 
</section> 

<section class="transparent" id="map1" data-background="mapbirdeye.jpg"></section>
<section id="map2" data-background="tornado.jpg">
<h3>images and research c/o<br /><a href="http://maker.uvic.ca/3dmodernism/" target="_blank">Alex Christie</a> + <a href="http://maker.uvic.ca/mudbox/" target="_blank">Katie Tanigawa</a></h3> 
</section>

<section id="kit" data-background="kit.png">
<h1>Stereoscope Kit</h1> 
<h3>uses CV to conduct a history of the senses<br />with an awareness of the mechanism</h3>
<h3>(in collaboration with <a href="http://maker.uvic.ca/kitsposter/" target="_blank">Devon Elliott, <br />Shaun Macpherson, Katie McQueston,<br />and William J. Turkel</a>)</h3> 
</section> 

<section class="transparent" id="stereo4" data-background="levitation.gif"></section> 
<section id="anaglyph" data-background="anaglyph.jpg">
<h3>images and research c/o <a href="http://devonelliott.net/2013/09/09/sense-of-depth/" target="_blank">Devon Elliott</a></h3> 
</section>

<section class="transparent" id="stereo2" data-background="stereo2.gif"></section> 
<section class="transparent" id="stereo1" data-background="stereo1.png"></section> 
<section id="stereo3" data-background="stereo3.png">
<h3>images and research c/o <a href="http://devonelliott.net/" target="_blank">Devon Elliott</a></h3> 
</section>

<section id="zaxis" data-background="end.png">
<h1>Humanities on <br />the Z-Axis</h1> 
<h3>depth | speculation | mediation | embodiment</h3>
<h3>(image care of <a href="http://maker.uvic.ca/ulysses/" target="_blank">Arthur Hain</a>)</h3>
</section>
</section> 

<section>
<section id="team" data-background="mlabteam.png">
<h1>Thank you, <br /><a  href="http://maker.uvic.ca/people/" target="_blank">Maker Lab team</a></h1>
<h3>Special thanks to Nina Belojevic, Alex Christie, Devon Elliott, Arthur Hain, Jon Johnson,<br /> Shaun Macpherson, Katie McQueston, Katie Tanigawa, and Zaqir Virani</h3>
<h3>Also to the Social Sciences and Humanities<br />Research Council and the Canadian Foundation<br />for Innovation</h3> 
</section>


<section id="thanks">
  <h1>Thank You, <a href="http://idrh.ku.edu/dhforum2013" target="_blank">#dhforum2013</a></h1>
  <h3>Special thanks to Arienne Dwyer, Brian Rosenblum, Germaine Halegoua, Whitney Trettien, Colin Allen, Alex Gil, and the IDRH.</h3>
  <h3>Keep in touch.</h3><h3><a href="https://twitter.com/jenterysayers" target="_blank">@jenterysayers</a> | <a href="mailto:jentery@uvic.ca">jentery@uvic.ca</a> | <a href="http://maker.uvic.ca/" target="_blank">maker.uvic.ca</a></h3>
</section>
</section> 

</div>
</div>
<script src="head.min.js"></script>
		<script src="reveal.min.js"></script>

		<script>

			Reveal.initialize({
        transition: 'concave',
        backgroundTransition: 'fade',
        transitionSpeed: "slow",
        controls: true,
        history: true,
        touch: true, 
        overview: true, 
        center: true,  
        rollingLinks: false // ANNOYING
      });

		</script>
</body>
</html>
